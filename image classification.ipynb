{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'Datasets/Train'\n",
    "valid_path = 'Datasets/Test'\n",
    "\n",
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "\n",
    "  \n",
    "  # useful for getting number of classes\n",
    "folders = glob(r'C:\\Users\\KIRAN\\Desktop\\Machine Learning\\facerecognition--cv2\\Deep-Learning-Face-Recognition/Datasets/Train/*')\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\KIRAN\\\\Desktop\\\\Machine Learning\\\\facerecognition--cv2\\\\Deep-Learning-Face-Recognition/Datasets/Train\\\\phani',\n",
       " 'C:\\\\Users\\\\KIRAN\\\\Desktop\\\\Machine Learning\\\\facerecognition--cv2\\\\Deep-Learning-Face-Recognition/Datasets/Train\\\\pk']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 50178     \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg.output)\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n",
    "\n",
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 74 images belonging to 2 classes.\n",
      "Found 65 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'r=model.fit_generator(training_set,\\n                         samples_per_epoch = 8000,\\n                         nb_epoch = 5,\\n                         validation_data = test_set,\\n                         nb_val_samples = 2000)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\KIRAN\\Desktop\\Machine Learning\\facerecognition--cv2\\Deep-Learning-Face-Recognition\\Datasets\\Train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(r'C:\\Users\\KIRAN\\Desktop\\Machine Learning\\facerecognition--cv2\\Deep-Learning-Face-Recognition\\Datasets\\Test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "'''r=model.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 5,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3/3 [==============================] - 88s 29s/step - loss: 1.0190 - accuracy: 0.5270 - val_loss: 8.5350e-05 - val_accuracy: 0.9692\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=1,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_accuracy')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('facefeatures_new_models.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]]\n",
      "[[1.0000000e+00 2.0178554e-35]]\n",
      "[[1. 0.]]\n",
      "[[1.000000e+00 3.188335e-25]]\n",
      "[[1.000000e+00 7.748613e-34]]\n",
      "[[1.0000000e+00 5.7266207e-21]]\n",
      "[[1.0000000e+00 2.3840333e-22]]\n",
      "[[1.0000000e+00 1.4962842e-22]]\n",
      "[[1.0000000e+00 1.4969754e-29]]\n",
      "[[1.0000000e+00 1.3064216e-23]]\n",
      "[[1.0000000e+00 1.3286223e-28]]\n",
      "[[1.0000000e+00 9.4966774e-23]]\n",
      "[[1.0000000e+00 7.8825243e-29]]\n",
      "[[1.000000e+00 7.562765e-27]]\n",
      "[[1.0000000e+00 2.2469811e-26]]\n",
      "[[1.0000000e+00 9.6960225e-25]]\n",
      "[[1.0000000e+00 1.4467021e-28]]\n",
      "[[1.0000000e+00 6.0427988e-28]]\n",
      "[[1.0000000e+00 1.5803871e-27]]\n",
      "[[1.0000000e+00 1.6197883e-31]]\n",
      "[[1.0000000e+00 3.7264977e-28]]\n",
      "[[1.000000e+00 4.331208e-31]]\n",
      "[[1.0000000e+00 1.4628497e-30]]\n",
      "[[1.0000000e+00 1.3574419e-32]]\n",
      "[[1.000000e+00 5.372409e-26]]\n",
      "[[1.0000000e+00 2.6390777e-28]]\n",
      "[[1.0000000e+00 4.5565985e-27]]\n",
      "[[1.0000000e+00 1.0317174e-27]]\n",
      "[[1.000000e+00 2.133383e-31]]\n",
      "[[1.000000e+00 6.780321e-30]]\n",
      "[[1.000000e+00 1.656571e-29]]\n",
      "[[1.0000000e+00 1.7566028e-29]]\n",
      "[[1.000000e+00 9.950076e-31]]\n",
      "[[1.000000e+00 6.908758e-28]]\n",
      "[[1.0000000e+00 3.1460819e-27]]\n",
      "[[1.000000e+00 3.493513e-30]]\n",
      "[[1.000000e+00 6.656095e-33]]\n",
      "[[1.000000e+00 5.917743e-28]]\n",
      "[[1.0000000e+00 2.0643342e-30]]\n",
      "[[1.0000000e+00 5.4702986e-30]]\n",
      "[[1.0000000e+00 1.6687376e-27]]\n",
      "[[1.0000000e+00 5.6628234e-27]]\n",
      "[[1.0000000e+00 1.3118203e-30]]\n",
      "[[1.0000000e+00 1.9480378e-26]]\n",
      "[[1.000000e+00 9.051928e-27]]\n",
      "[[1.0000000e+00 1.6247903e-29]]\n",
      "[[1.0000000e+00 3.2807145e-29]]\n",
      "[[1.0000000e+00 4.3299712e-30]]\n",
      "[[1.0000000e+00 1.4322513e-33]]\n",
      "[[1.0000000e+00 2.6400563e-34]]\n",
      "[[1.000000e+00 6.891158e-33]]\n",
      "[[1.000000e+00 5.113555e-34]]\n",
      "[[1.000000e+00 2.012952e-26]]\n",
      "[[1.000000e+00 6.508826e-27]]\n",
      "[[1.00000e+00 8.36075e-27]]\n",
      "[[1.000000e+00 7.926945e-28]]\n",
      "[[1.000000e+00 1.634479e-25]]\n",
      "[[1.0000000e+00 1.4011406e-25]]\n",
      "[[1.0000000e+00 2.1375255e-27]]\n",
      "[[1.000000e+00 6.294093e-29]]\n",
      "[[1.000000e+00 2.192041e-28]]\n",
      "[[1.000000e+00 7.363819e-29]]\n",
      "[[1.000000e+00 1.240947e-28]]\n",
      "[[1.0000000e+00 1.6391261e-23]]\n",
      "[[1.0000000e+00 1.8495718e-26]]\n",
      "[[1.0000000e+00 2.0934993e-25]]\n",
      "[[1.0000000e+00 2.0162411e-26]]\n",
      "[[1.0000000e+00 4.6014395e-26]]\n",
      "[[1.000000e+00 9.693313e-27]]\n",
      "[[1.000000e+00 7.370643e-23]]\n",
      "[[1.000000e+00 1.935704e-26]]\n",
      "[[1.0000000e+00 1.2368649e-26]]\n",
      "[[1.0000000e+00 4.3457004e-26]]\n",
      "[[1.0000000e+00 7.7078605e-29]]\n",
      "[[1.0000000e+00 3.5521577e-30]]\n",
      "[[1.0000000e+00 9.4319245e-27]]\n",
      "[[1.000000e+00 4.593315e-28]]\n",
      "[[1.0000000e+00 1.5455975e-28]]\n",
      "[[1.00000e+00 8.48367e-27]]\n",
      "[[1.0000000e+00 3.3213676e-26]]\n",
      "[[1.0000000e+00 2.1993793e-27]]\n",
      "[[1.00000000e+00 1.02844135e-25]]\n",
      "[[1.000000e+00 8.551093e-26]]\n",
      "[[1.0000000e+00 2.0037528e-24]]\n",
      "[[1.0000000e+00 1.8666155e-29]]\n",
      "[[1.0000000e+00 3.8175011e-22]]\n",
      "[[1.0000000e+00 5.7221237e-28]]\n",
      "[[1.0000000e+00 3.4080103e-28]]\n",
      "[[1.0000000e+00 1.0853062e-25]]\n",
      "[[1.000000e+00 8.136855e-25]]\n",
      "[[1.0000000e+00 2.8495202e-28]]\n",
      "[[1. 0.]]\n",
      "[[1. 0.]]\n",
      "[[1.0000000e+00 2.5763285e-30]]\n",
      "[[1.0000000e+00 1.2842984e-32]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-036360e6169f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mvideo_capture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo_capture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;31m#canvas = detect(gray, frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m#image, face =face_detector(frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "# Face Recognition\n",
    "\n",
    "# Importing the libraries\n",
    "from PIL import Image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "model = load_model('facefeatures_new_models.h5')\n",
    "\n",
    "# Loading the cascades\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Doing some Face Recognition with the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    #canvas = detect(gray, frame)\n",
    "    #image, face =face_detector(frame)\n",
    "    \n",
    "    face=face_extractor(frame)\n",
    "    if type(face) is np.ndarray:\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "        im = Image.fromarray(face, 'RGB')\n",
    "           #Resizing into 128x128 because we trained the model with this image size.\n",
    "        img_array = np.array(im)\n",
    "                    #Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "                    #So changing dimension 128x128x3 into 1x128x128x3 \n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        pred = model.predict(img_array)\n",
    "        print(pred)\n",
    "                     \n",
    "        name=\"None matching\"\n",
    "        \n",
    "        if(pred[0][0]>0.5):\n",
    "            name='Phani'\n",
    "        cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame,\"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
