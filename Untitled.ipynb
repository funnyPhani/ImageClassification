{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]]\n",
      "[[1.0000000e+00 6.0421474e-30]]\n",
      "[[1.000000e+00 9.170506e-29]]\n",
      "[[1.0000000e+00 1.2320077e-22]]\n",
      "[[1.0000000e+00 2.2883993e-33]]\n",
      "[[1.000000e+00 9.205146e-34]]\n",
      "[[1.0000000e+00 3.0073031e-30]]\n",
      "[[1.0000000e+00 1.9123541e-29]]\n",
      "[[1.0000000e+00 7.6376305e-25]]\n",
      "[[1.0000000e+00 3.1860946e-27]]\n",
      "[[1.00000e+00 5.82203e-32]]\n",
      "[[1.000000e+00 8.725829e-28]]\n",
      "[[1.000000e+00 6.805655e-25]]\n",
      "[[1.000000e+00 7.308608e-28]]\n",
      "[[1.0000000e+00 4.6621645e-27]]\n",
      "[[1.0000000e+00 1.9276004e-24]]\n",
      "[[1.000000e+00 5.541785e-26]]\n",
      "[[1.000000e+00 4.530888e-22]]\n",
      "[[1.00000000e+00 1.21977556e-20]]\n",
      "[[1.0000000e+00 1.5028879e-19]]\n",
      "[[1.0000000e+00 1.9831647e-27]]\n",
      "[[1.0000000e+00 1.5061417e-27]]\n",
      "[[1.0000000e+00 2.8583567e-23]]\n",
      "[[1.0000000e+00 1.9664139e-24]]\n",
      "[[1.0000000e+00 2.2661744e-21]]\n",
      "[[1.0000000e+00 3.5914017e-28]]\n",
      "[[1.0000000e+00 6.6761976e-29]]\n",
      "[[1.00000e+00 6.29808e-29]]\n",
      "[[1.0000000e+00 1.0787927e-25]]\n",
      "[[1.0000000e+00 1.4810899e-19]]\n",
      "[[1.0000000e+00 3.4243983e-24]]\n",
      "[[1.0000000e+00 2.4875307e-20]]\n",
      "[[1.0000000e+00 1.5769252e-26]]\n",
      "[[1.000000e+00 2.069466e-31]]\n",
      "[[1.0000000e+00 1.2359864e-28]]\n",
      "[[1.0000000e+00 1.2394142e-28]]\n",
      "[[1.000000e+00 2.367533e-27]]\n",
      "[[1.0000000e+00 2.7285087e-27]]\n",
      "[[1.000000e+00 2.035839e-28]]\n",
      "[[1. 0.]]\n",
      "[[1.000000e+00 3.993598e-31]]\n",
      "[[1.0000000e+00 4.5520477e-34]]\n",
      "[[1.000000e+00 8.959439e-29]]\n",
      "[[1.000000e+00 8.845137e-28]]\n",
      "[[1.0000000e+00 8.2345997e-23]]\n",
      "[[1.0000000e+00 2.4203757e-22]]\n",
      "[[1.000000e+00 5.986989e-23]]\n",
      "[[1.00000e+00 4.08136e-28]]\n",
      "[[1.00000e+00 2.72492e-27]]\n",
      "[[1.000000e+00 3.599212e-32]]\n",
      "[[1.000000e+00 6.461278e-27]]\n",
      "[[1.0000000e+00 1.1517601e-25]]\n",
      "[[1.0000000e+00 3.3393593e-32]]\n",
      "[[1.0000000e+00 1.8341336e-28]]\n",
      "[[1.000000e+00 7.154876e-27]]\n",
      "[[1.0000000e+00 1.0608345e-29]]\n",
      "[[1.000000e+00 8.978491e-30]]\n",
      "[[1.000000e+00 4.105702e-37]]\n",
      "[[1.0000000e+00 5.5696926e-35]]\n",
      "[[1.0000000e+00 1.1971486e-31]]\n",
      "[[1.000000e+00 7.816471e-36]]\n",
      "[[1.0000000e+00 3.1828704e-30]]\n",
      "[[1.0000000e+00 8.2506737e-29]]\n",
      "[[1.0000000e+00 1.2103654e-29]]\n",
      "[[1.0000000e+00 2.0664909e-32]]\n",
      "[[1.0000000e+00 1.3841834e-32]]\n",
      "[[1.0000000e+00 4.6308974e-27]]\n",
      "[[1.00000000e+00 1.30914675e-36]]\n",
      "[[1.000000e+00 4.027478e-27]]\n",
      "[[1.0000000e+00 1.7651938e-22]]\n",
      "[[1.0000000e+00 2.9429623e-33]]\n",
      "[[1.0000000e+00 2.5538817e-30]]\n",
      "[[1.0000000e+00 4.5396303e-27]]\n",
      "[[1.0000000e+00 2.1390406e-29]]\n",
      "[[1.0000000e+00 4.0128224e-32]]\n",
      "[[1.000000e+00 9.328981e-26]]\n",
      "[[1.0000000e+00 4.2983143e-27]]\n",
      "[[1.000000e+00 3.762884e-34]]\n",
      "[[1.000000e+00 5.567673e-28]]\n",
      "[[1.000000e+00 3.191736e-29]]\n",
      "[[1.0000000e+00 1.1365922e-19]]\n",
      "[[1.0000000e+00 4.4028643e-20]]\n",
      "[[1.000000e+00 2.882059e-17]]\n",
      "[[1.0000000e+00 1.0252901e-21]]\n",
      "[[1.000000e+00 4.862915e-23]]\n",
      "[[1.0000000e+00 3.2057783e-23]]\n",
      "[[1.0000000e+00 5.5943917e-28]]\n",
      "[[1.000000e+00 7.075135e-27]]\n",
      "[[1.0000000e+00 4.0253276e-27]]\n",
      "[[1.000000e+00 7.288441e-23]]\n",
      "[[1.0000000e+00 1.1041955e-23]]\n",
      "[[1.0000000e+00 2.9545153e-25]]\n",
      "[[1.0000000e+00 4.5544853e-24]]\n",
      "[[1.0000000e+00 2.1556852e-22]]\n",
      "[[1.0000000e+00 4.9631865e-28]]\n",
      "[[1.000000e+00 9.762271e-25]]\n",
      "[[1.0000000e+00 8.5537427e-32]]\n",
      "[[1.000000e+00 6.443264e-26]]\n",
      "[[1.0000000e+00 4.5293014e-28]]\n",
      "[[1.0000000e+00 2.7385475e-29]]\n",
      "[[1.0000000e+00 1.6591205e-28]]\n",
      "[[1.0000000e+00 4.1350363e-27]]\n",
      "[[1.0000000e+00 1.8798219e-28]]\n",
      "[[1.0000000e+00 4.9749744e-29]]\n",
      "[[1.0000000e+00 3.2378992e-34]]\n",
      "[[1.0000000e+00 4.1449522e-28]]\n",
      "[[1.0000000e+00 2.1498863e-38]]\n",
      "[[1. 0.]]\n",
      "[[1.0000000e+00 2.5035956e-31]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-74a83f6c11c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m#image, face =face_detector(frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mface\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mface_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-74a83f6c11c4>\u001b[0m in \u001b[0;36mface_extractor\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfaces\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "# Face Recognition\n",
    "\n",
    "# Importing the libraries\n",
    "from PIL import Image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "model = load_model('facefeatures_new_models.h5')\n",
    "\n",
    "# Loading the cascades\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Doing some Face Recognition with the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    #canvas = detect(gray, frame)\n",
    "    #image, face =face_detector(frame)\n",
    "    \n",
    "    face=face_extractor(frame)\n",
    "    if type(face) is np.ndarray:\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "        im = Image.fromarray(face, 'RGB')\n",
    "           #Resizing into 128x128 because we trained the model with this image size.\n",
    "        img_array = np.array(im)\n",
    "                    #Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "                    #So changing dimension 128x128x3 into 1x128x128x3 \n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        pred = model.predict(img_array)\n",
    "        print(pred)\n",
    "                     \n",
    "        name=\"None matching\"\n",
    "        \n",
    "        if(pred[0][0]>0.5):\n",
    "            name='Phani'\n",
    "        cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame,\"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
